# Semantic Similarity Search and Ranking for arXiv Research Papers
### Using TFâ€“IDF, BM25, Sentence-BERT, and FAISS

This project implements a semantic similarity search engine for academic research papers using **arXiv abstract data**. It evaluates and compares traditional keyword-based retrieval models (TFâ€“IDF, BM25) with modern embedding-based semantic search (Sentence-BERT + FAISS). The system is fully modular, GPU-aware, batch-optimized, and supports real-time interactive querying along with quantitative evaluation through **Precision@K**.

---

## ğŸš€ Features

### ğŸ” Multi-Model Retrieval
The search engine provides three retrieval strategies:

| Model | Type | Description |
|-------|------|-------------|
| **TFâ€“IDF** | Traditional | Sparse lexical vector representation via scikit-learn |
| **BM25** | Probabilistic | Strong keyword-based baseline for document ranking |
| **Sentence-BERT** | Semantic | Dense contextual embeddings capturing meaning, not just keywords |

---

### âš¡ High-Performance Search (FAISS)
- Sentence-BERT embeddings indexed using **FAISS** for fast nearest-neighbor lookup.
- Uses **inner-product search** with L2-normalized vectors.
- Automatically falls back to cosine similarity if FAISS is disabled.

---

### ğŸ§± Modular Architecture (6 Files)
The codebase is divided into exactly **six core implementation files**, aligned with assignment requirements:

```
config.py
data_loader.py
text_representation.py
search_engine.py
evaluation.py
main.py
```

Additional supporting files:

```
test_semantic_search.py
requirements.txt
README.md
```

Each function includes standardized header-style comments for clarity.

---

### âš™ï¸ GPU/CPU Auto-Detection
The system automatically selects the optimal compute device:

- Uses **CUDA GPU**, if available  
- Falls back to **CPU** with clean messages (no warnings)

---

### ğŸš€ Batch Processing for Speed
Batch encoding is used for all embedding operations to maximize throughput. This dramatically speeds up processing when handling 100â€“500 arXiv abstracts.

---

### ğŸ“Š Precision@K Evaluation
Implements category-based evaluation using:

- P@1  
- P@3  
- P@5  
- P@10

This measures the proportion of retrieved papers that share the same **arXiv category** as the query.

---

### ğŸ› Interactive Search Mode
After evaluation, the program switches to an interactive mode:

```
Enter an abstract or description:
```

Returns ranked papers with:

- Rank
- Similarity score
- arXiv ID
- Category
- Title
- Abstract snippet

---

## ğŸ“ Folder Structure

```
project/
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ data_loader.py
â”œâ”€â”€ text_representation.py
â”œâ”€â”€ search_engine.py
â”œâ”€â”€ evaluation.py
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ test_semantic_search.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Project

### **1. Full pipeline (evaluation + interactive search)**

```bash
python main.py
```

### **2. Only interactive search (skip evaluation)**

```bash
python main.py --no-eval
```

### **3. Choose retrieval model**

```bash
python main.py --model tfidf
python main.py --model bm25
python main.py --model bert
```

### **4. Change number of results returned**

```bash
python main.py --topk 15
```

---

## ğŸ§ª Running Unit Tests

```bash
python -m unittest test_semantic_search.py
```

This validates:

- Text preprocessing  
- Device selection (GPU/CPU)  
- Embedding shape consistency  
- Overall search engine correctness  

---

## ğŸ” How the arXiv API Works

The project uses the official `arxiv` Python library.

Example call:

```python
search = arxiv.Search(
    query="cat:cs.LG",
    max_results=150,
    sort_by=arxiv.SortCriterion.SubmittedDate
)
```

Each returned `result` object contains:

- title  
- summary (abstract)  
- primary_category  
- published date  
- id (via `get_short_id()`)  

Abstracts are normalized and fed into the vectorization/embedding pipeline.

---

## ğŸ“ Alignment With Assignment Requirements

| Requirement | Status | Explanation |
|------------|--------|-------------|
| Use arXiv API | âœ”ï¸ | arxiv library used for metadata retrieval |
| TFâ€“IDF, BM25 models | âœ”ï¸ | Implemented and benchmarked |
| Neural semantic model | âœ”ï¸ | Sentence-BERT embeddings |
| Cosine similarity & FAISS | âœ”ï¸ | Both included |
| GPU/CPU, batching | âœ”ï¸ | Device auto-selection + batch encoding |
| Precision@K | âœ”ï¸ | Category-based evaluation |
| Modular files (â‰¤6) | âœ”ï¸ | Exactly six implementation files |
| Header comments | âœ”ï¸ | Added before every method |
| Interactive system | âœ”ï¸ | CLI interface implemented |

---

## ğŸ“š Possible Extensions

- Persist FAISS index to disk
- Cache arXiv results to speed up development
- Add a simple web interface (Flask or FastAPI)
- Add visualization (TSNE of embeddings)

---

## ğŸ“œ License
Free for academic, educational, and research use.
